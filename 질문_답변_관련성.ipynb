{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f51add1",
   "metadata": {},
   "source": [
    "# 시스템 설정\n",
    "채점자는 검색된 문서와 사용자 질문의 관련성을 평가하는 채점자입니다.\n",
    "문서에 사용자 질문과 관련된 키워드 또는 의미론적 의미가 포함되어 있으면 관련성이 있는 것으로 채점합니다. \\n\n",
    "엄격한 테스트일 필요는 없습니다. 잘못된 검색을 걸러내는 것이 목표입니다. \\n\n",
    "1 또는 0의 이진 점수를 부여합니다. 여기서 1은 해당 문서가 질문과 관련이 있음을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d944e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 설정\n",
    "system = f\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "\n",
    "It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "\n",
    "Give a binary score 1 or 0 score, where 1 means that the document is relevant to the question.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a8df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key 입력: ········\n",
      "=====================\n",
      "질문을 입력하세요: 문서를 요약해줘\n",
      "Debug Output: 문서를 요약해줘\n",
      "Debug Output: {'context': [], 'question': '문서를 요약해줘'}\n",
      "Final Response: \n",
      "Score: 1\n",
      "=====================\n",
      "질문을 입력하세요: exit\n",
      "대답: 즐거운 대화였어요.\n"
     ]
    }
   ],
   "source": [
    "# KEY설정\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")\n",
    "\n",
    "# 모델로드\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000)\n",
    "\n",
    "# 파일 로드\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"초거대언어모델연구동향.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    utf8_docs = [doc.page_content.encode('utf-8').decode('utf-8') for doc in docs]\n",
    "\n",
    "# 문서 청크 나누기 2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "    \n",
    "# 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# 리트리버 변환\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "\n",
    "# 템플릿 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 시스템 설정\n",
    "System = f\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "\n",
    "It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "\n",
    "Give a binary score 1 or 0 score, where 1 means that the document is relevant to the question.\"\"\"\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", System),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n",
    "\n",
    "# 질문 응답 체인 구성\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# 질문 반복 처리\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,   # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()     # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()| contextual_prompt | model\n",
    "\n",
    "# 출력\n",
    "while True:\n",
    "    print('=====================')\n",
    "    query = input(\"질문을 입력하세요: \")\n",
    "\n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    \n",
    "    print(\"Final Response: \")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a4345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
