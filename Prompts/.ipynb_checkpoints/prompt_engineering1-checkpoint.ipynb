{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2cd91a",
   "metadata": {},
   "source": [
    "## 수정 사항\n",
    "1. 백업 스토어 설정에서 InMemoryDocstore를 사용해보기\n",
    "2. 파라미터 조정\n",
    "3. 프롬프트에 명령 추가\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b37a29",
   "metadata": {},
   "source": [
    "## 백터 스토어 설정에서 InMemoryDocstore를 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50948e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379944b3",
   "metadata": {},
   "source": [
    "## 파라미터 조정\n",
    "\n",
    "- 모델 지정에서 파라미터 추가(temperature, max_tokens)\n",
    "- 리트리버 변환에서 k값 변경(1->2)\n",
    "- 모델 로드에 UTF-8 추가\n",
    "\n",
    "\n",
    "### 리트리버 파라미터 설명\n",
    "- search_type\n",
    " - similarity: 벡터간 유사도, 내적 사용 검색\n",
    " - mmr: 다양성 고려 검색\n",
    " - approx: 근사적 검색(대규모 데이터셋에서 빠른 검색)\n",
    "\n",
    "- search_kwargs\n",
    " - k: 반환할 결과의 수 \n",
    " - lambda_mult: 유사도와 다양성 간의 균형 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4005aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로드\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"초거대언어모델연구동향.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    utf8_docs = [doc.page_content.encode('utf-8').decode('utf-8') for doc in docs]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79c0c8",
   "metadata": {},
   "source": [
    "## 프롬프트에 추가 명령\n",
    "\n",
    "- system: 인공지능 모델 연구자이십니다. 이 문서에서는 발전, 과제 및 주요 기여를 포함하여 초대형 언어 모델의 최신 연구 동향을 설명합니다. 귀하의 임무는 문서를 분석하고 상세하고 통찰력 있는 답변을 제공하는 것입니다.\n",
    "- user: 본 문서에 언급된 주요 동향과 연구 결과를 중심으로 포괄적인 답변을 부탁드립니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an artificial intelligence model researcher. The document describes the latest research trends in super-large language models, including advancements, challenges, and key contributions. Your task is to analyze the document and provide a detailed and insightful response.\"),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995541e9",
   "metadata": {},
   "source": [
    "# 수정 본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f5a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key 입력: ········\n"
     ]
    }
   ],
   "source": [
    "# KEY설정\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")\n",
    "\n",
    "# 모델로드\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000)\n",
    "\n",
    "# 파일 로드\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"초거대언어모델연구동향.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    utf8_docs = [doc.page_content.encode('utf-8').decode('utf-8') for doc in docs]\n",
    "\n",
    "# 문서 청크 나누기 2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "    \n",
    "# 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# 리트리버 변환\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "\n",
    "# 템플릿 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an artificial intelligence model researcher. The document describes the latest research trends in super-large language models, including advancements, challenges, and key contributions. Your task is to analyze the document and provide a detailed and insightful response.\"),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n",
    "\n",
    "# 질문 응답 체인 구성\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# 질문 반복 처리\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,   # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()     # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()| contextual_prompt | model\n",
    "\n",
    "# 출력\n",
    "while True:\n",
    "    print('=====================')\n",
    "    query = input(\"질문을 입력하세요: \")\n",
    "\n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    \n",
    "    print(\"Final Response: \")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5a138",
   "metadata": {},
   "source": [
    "# 1.\n",
    "- 질문: 최근 초거대 언어모델 연구동향을 알려줘\n",
    "- 대답: 깔끔하게 정리 되었고 내용에 맞는 대답을 한다.\n",
    "\n",
    "# 2. \n",
    "- 질문: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 설명해주세요\n",
    "- 대답: 갑자기 영어로 대답을하여 놀랐다. 내용은 초대형 언어 모델 배포의 윤리적 영향과 사회적 영향을 말하고있다.\n",
    "\n",
    "# 3.\n",
    "- 질문: 방금전 글을 한글로 말해줘\n",
    "- 대답: 첫 번째 질문을 그대로 가져왔다. \n",
    "\n",
    "# 4.\n",
    "- 질문: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 한글로 설명해주세요 (한글로 설명 부탁)\n",
    "- 대답: 질문에 관련없는 내용이 나옴\n",
    "\n",
    "\n",
    "## 프롬프트에서 바꾸어야할 점\n",
    "\n",
    "### 이전 프롬프트\n",
    "- system: 인공지능 모델 연구자이십니다. 이 문서에서는 발전, 과제 및 주요 기여를 포함하여 초대형 언어 모델의 최신 연구 동향을 설명합니다. 귀하의 임무는 문서를 분석하고 상세하고 통찰력 있는 답변을 제공하는 것입니다.\n",
    "- user: 본 문서에 언급된 주요 동향과 연구 결과를 중심으로 포괄적인 답변을 부탁드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e166724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
