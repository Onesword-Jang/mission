{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa91fc61",
   "metadata": {},
   "source": [
    "## 수정 사항\n",
    "1. 백업 스토어 설정에서 InMemoryDocstore를 사용해보기\n",
    "2. 파라미터 조정\n",
    "3. 프롬프트에 명령 추가\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e4d08",
   "metadata": {},
   "source": [
    "## 백터 스토어 설정에서 InMemoryDocstore를 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3105b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51aa10",
   "metadata": {},
   "source": [
    "## 파라미터 조정\n",
    "\n",
    "- 모델 지정에서 파라미터 추가(temperature, max_tokens)\n",
    "- 리트리버 변환에서 k값 변경(1->2)\n",
    "- 모델 로드에 UTF-8 추가\n",
    "\n",
    "\n",
    "### 리트리버 파라미터 설명\n",
    "- search_type\n",
    " - similarity: 벡터간 유사도, 내적 사용 검색\n",
    " - mmr: 다양성 고려 검색\n",
    " - approx: 근사적 검색(대규모 데이터셋에서 빠른 검색)\n",
    "\n",
    "- search_kwargs\n",
    " - k: 반환할 결과의 수 \n",
    " - lambda_mult: 유사도와 다양성 간의 균형 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4107f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28358a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로드\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"초거대언어모델연구동향.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    utf8_docs = [doc.page_content.encode('utf-8').decode('utf-8') for doc in docs]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6483c1",
   "metadata": {},
   "source": [
    "## 프롬프트에 추가 명령\n",
    "\n",
    "- system: 인공지능 모델 연구자이십니다. 이 문서에서는 발전, 과제 및 주요 기여를 포함하여 초대형 언어 모델의 최신 연구 동향을 설명합니다. 귀하의 임무는 문서를 분석하고 상세하고 통찰력 있는 답변을 제공하는 것입니다.\n",
    "- user: 본 문서에 언급된 주요 동향과 연구 결과를 중심으로 포괄적인 답변을 부탁드립니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an artificial intelligence model researcher. The document describes the latest research trends in super-large language models, including advancements, challenges, and key contributions. Your task is to analyze the document and provide a detailed and insightful response.\"),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a732c6",
   "metadata": {},
   "source": [
    "# 수정 본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd5c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key 입력: ········\n",
      "=====================\n",
      "질문을 입력하세요: 최근 초거대 언어모델 연구동향을 알려줘\n",
      "Debug Output: 최근 초거대 언어모델 연구동향을 알려줘\n",
      "Debug Output: {'context': [], 'question': '최근 초거대 언어모델 연구동향을 알려줘'}\n",
      "Final Response: \n",
      "최근 초거대 언어모델(LLM) 연구동향은 여러 가지 중요한 발전과 도전 과제를 포함하고 있습니다. 다음은 주요 트렌드와 연구 결과에 대한 종합적인 분석입니다.\n",
      "\n",
      "1. **모델 크기와 성능**: 초거대 언어모델의 크기는 계속해서 증가하고 있으며, 이는 모델의 성능 향상에 기여하고 있습니다. 많은 연구자들이 파라미터 수를 늘리는 것뿐만 아니라, 더 정교한 아키텍처를 개발하여 모델의 이해력과 생성 능력을 개선하고 있습니다. 예를 들어, 최근의 연구에서는 수백억 개의 파라미터를 가진 모델들이 다양한 자연어 처리(NLP) 작업에서 이전 모델들보다 우수한 성능을 보이고 있습니다.\n",
      "\n",
      "2. **효율성 개선**: 모델의 크기가 커짐에 따라 계산 자원과 에너지 소비에 대한 우려도 커지고 있습니다. 이에 따라 연구자들은 모델의 효율성을 높이기 위한 다양한 방법을 모색하고 있습니다. 예를 들어, 지식 증류(knowledge distillation), 프루닝(pruning), 양자화(quantization) 등의 기법이 활용되어, 성능을 유지하면서도 더 적은 자원으로 모델을 운영할 수 있는 방안이 연구되고 있습니다.\n",
      "\n",
      "3. **다양한 활용 사례**: 초거대 언어모델은 다양한 분야에서 활용되고 있습니다. 특히, 고객 서비스, 콘텐츠 생성, 코드 작성, 번역 등 여러 산업에서 실제 적용 사례가 증가하고 있습니다. 이러한 활용은 모델의 상용화 가능성을 높이고 있으며, 기업들이 LLM을 통해 비즈니스 가치를 창출하는 데 기여하고 있습니다.\n",
      "\n",
      "4. **윤리적 고려와 편향 문제**: LLM의 발전과 함께 윤리적 문제와 편향(bias) 문제도 중요한 연구 주제로 떠오르고 있습니다. 모델이 학습하는 데이터에 포함된 편향이 결과에 영향을 미칠 수 있으며, 이는 사회적 문제를 야기할 수 있습니다. 이에 따라, 연구자들은 공정성(fairness)과 투명성(transparency)을 확보하기 위한 방법론을 개발하고 있으며, 모델의 결과를 평가하고 조정하는 방법에 대한 연구가 활발히 진행되고 있습니다.\n",
      "\n",
      "5. **멀티모달 모델**: 최근에는 텍스트뿐만 아니라 이미지, 비디오 등 다양한 형태의 데이터를 처리할 수 있는 멀티모달 모델에 대한 연구도 증가하고 있습니다. 이러한 모델은 다양한 입력을 통합하여 더 풍부한 이해와 생성 능력을 제공할 수 있으며, 이는 AI의 응용 범위를 넓히는 데 기여하고 있습니다.\n",
      "\n",
      "6. **오픈 소스와 협업**: 초거대 언어모델의 연구는 오픈 소스 커뮤니티와의 협업을 통해 더욱 활성화되고 있습니다. 많은 연구자들이 모델과 데이터를 공개하여, 보다 많은 사람들이 연구에 참여하고, 혁신적인 아이디어를 공유할 수 있는 환경을 조성하고 있습니다.\n",
      "\n",
      "결론적으로, 초거대 언어모델 연구는 성능 향상, 효율성 개선, 윤리적 고려, 멀티모달 접근 등 다양한 측면에서 활발히 진행되고 있으며, 이는 앞으로의 AI 발전에 중요한 기여를 할 것으로 기대됩니다.\n",
      "=====================\n",
      "질문을 입력하세요: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 설명해주세요\n",
      "Debug Output: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 설명해주세요\n",
      "Debug Output: {'context': [], 'question': '각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 설명해주세요'}\n",
      "Final Response: \n",
      "In analyzing the latest research trends in super-large language models, several key themes emerge that highlight both advancements and challenges in this rapidly evolving field. Among these, I believe the most critical topic is the ethical implications and societal impact of deploying super-large language models. Here’s why:\n",
      "\n",
      "1. **Ethical Considerations**: As language models grow in size and capability, they also raise significant ethical concerns. Issues such as bias, misinformation, and the potential for misuse become more pronounced. Research has shown that larger models can inadvertently amplify biases present in their training data, leading to harmful stereotypes and unfair treatment of certain groups. Addressing these ethical challenges is paramount to ensure that advancements in AI benefit all of society rather than exacerbate existing inequalities.\n",
      "\n",
      "2. **Accountability and Transparency**: With the increasing complexity of super-large models, understanding their decision-making processes becomes more challenging. This lack of transparency can lead to a trust deficit among users and stakeholders. Research trends are focusing on developing methods for interpretability and accountability, which are essential for responsible AI deployment. Ensuring that these models can be audited and understood is crucial for their acceptance and safe integration into society.\n",
      "\n",
      "3. **Environmental Impact**: The training of super-large language models requires substantial computational resources, leading to significant energy consumption and carbon emissions. Recent studies have highlighted the environmental footprint of these models, prompting researchers to explore more sustainable approaches. This includes optimizing algorithms for efficiency, developing smaller models that retain performance, and utilizing renewable energy sources for training. Addressing the environmental impact is critical not only for the sustainability of AI research but also for aligning with global climate goals.\n",
      "\n",
      "4. **User Interaction and Accessibility**: As language models become more integrated into everyday applications, understanding user interaction and ensuring accessibility is vital. Research is increasingly focusing on how diverse user groups interact with these models and how to design interfaces that are inclusive. This trend emphasizes the importance of making advanced AI technologies available to a broader audience, including those with disabilities or limited technical expertise.\n",
      "\n",
      "5. **Regulatory Frameworks**: The rapid advancement of super-large language models has outpaced the development of regulatory frameworks. There is a growing recognition of the need for policies that govern the use of AI technologies, ensuring they are used ethically and responsibly. Research is exploring how to balance innovation with regulation, aiming to create guidelines that protect users while fostering technological advancement.\n",
      "\n",
      "In conclusion, while advancements in super-large language models are remarkable, the ethical implications and societal impact of these technologies stand out as the most critical area of focus. Addressing these challenges is essential for the responsible development and deployment of AI, ensuring that it serves the greater good and contributes positively to society. As researchers continue to push the boundaries of what language models can achieve, it is imperative that they also prioritize ethical considerations, transparency, sustainability, user accessibility, and regulatory frameworks to navigate the complexities of this powerful technology.\n",
      "=====================\n",
      "질문을 입력하세요: 방금전 글을 한글로 말해줘\n",
      "Debug Output: 방금전 글을 한글로 말해줘\n",
      "Debug Output: {'context': [], 'question': '방금전 글을 한글로 말해줘'}\n",
      "Final Response: \n",
      "최근 초대형 언어 모델에 대한 연구 동향은 여러 가지 중요한 발전과 도전 과제를 포함하고 있습니다. 다음은 이 분야에서의 주요 트렌드와 연구 결과를 정리한 것입니다.\n",
      "\n",
      "1. **모델 크기와 성능**: 초대형 언어 모델은 그 크기가 증가함에 따라 성능이 향상되는 경향을 보이고 있습니다. 특히, 수십억 개의 매개변수를 가진 모델들이 다양한 자연어 처리(NLP) 작업에서 이전 모델들보다 월등한 성능을 보여주고 있습니다. 이러한 경향은 더 많은 데이터와 계산 자원을 활용하여 모델을 훈련시키는 방식으로 이어지고 있습니다.\n",
      "\n",
      "2. **효율성 문제**: 모델의 크기가 커짐에 따라 계산 비용과 에너지 소비도 증가하고 있습니다. 이에 따라 연구자들은 효율적인 훈련 및 추론 방법을 개발하는 데 집중하고 있습니다. 예를 들어, 지식 증류(knowledge distillation)와 같은 기법을 통해 더 작은 모델이 큰 모델의 성능을 모방할 수 있도록 하는 연구가 활발히 진행되고 있습니다.\n",
      "\n",
      "3. **윤리적 고려사항**: 초대형 언어 모델의 사용이 증가함에 따라 윤리적 문제도 대두되고 있습니다. 편향된 데이터로 훈련된 모델이 사회적 편견을 강화할 수 있다는 우려가 있으며, 이를 해결하기 위한 연구가 필요합니다. 또한, 모델의 투명성과 설명 가능성을 높이기 위한 노력도 중요해지고 있습니다.\n",
      "\n",
      "4. **다양한 응용 분야**: 초대형 언어 모델은 기계 번역, 텍스트 생성, 질문 응답 시스템 등 다양한 분야에서 활용되고 있습니다. 특히, 특정 도메인에 특화된 모델 개발이 활발히 이루어지고 있으며, 이는 특정 산업의 요구에 맞춘 맞춤형 솔루션을 제공하는 데 기여하고 있습니다.\n",
      "\n",
      "5. **협업과 오픈 소스**: 연구자들 사이의 협업이 증가하고 있으며, 오픈 소스 모델과 데이터셋의 공유가 활발히 이루어지고 있습니다. 이는 연구의 투명성을 높이고, 다양한 연구자들이 초대형 모델을 활용할 수 있는 기회를 제공합니다.\n",
      "\n",
      "이러한 트렌드는 초대형 언어 모델의 발전 방향을 제시하며, 앞으로의 연구에서 해결해야 할 과제들을 명확히 하고 있습니다. 연구자들은 이러한 도전 과제를 극복하기 위해 지속적으로 혁신적인 방법을 모색하고 있습니다.\n",
      "=====================\n",
      "질문을 입력하세요: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 한글로 설명해주세요\n",
      "Debug Output: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 한글로 설명해주세요\n",
      "Debug Output: {'context': [], 'question': '각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 한글로 설명해주세요'}\n",
      "Final Response: \n",
      "최근의 연구 동향을 살펴보면, 초대형 언어 모델(Super-large language models)의 발전은 인공지능 분야에서 매우 중요한 이슈로 부각되고 있습니다. 이 모델들은 자연어 처리(NLP)에서의 성능을 극대화하고, 다양한 응용 분야에서 혁신적인 변화를 가져오고 있습니다. 다음은 이와 관련된 주요 트렌드와 연구 결과를 분석한 내용입니다.\n",
      "\n",
      "1. **모델 크기와 성능의 상관관계**: 초대형 언어 모델은 그 크기가 커질수록 성능이 향상되는 경향이 있습니다. 이는 더 많은 파라미터와 데이터로 학습할 수 있기 때문이며, 복잡한 언어 패턴을 이해하고 생성하는 데 유리합니다. 그러나 이러한 경향은 비용과 자원 소모의 증가를 동반하므로, 효율적인 모델 설계가 필요합니다.\n",
      "\n",
      "2. **전이 학습과 파인튜닝**: 초대형 언어 모델은 사전 학습(pre-training) 후 특정 작업에 맞춰 파인튜닝(fine-tuning)하는 방식으로 활용됩니다. 이는 다양한 도메인에서의 적용 가능성을 높이며, 적은 데이터로도 높은 성능을 발휘할 수 있게 합니다. 이러한 접근법은 특히 데이터가 부족한 분야에서 유용하게 사용됩니다.\n",
      "\n",
      "3. **윤리적 고려사항**: 초대형 언어 모델의 발전은 윤리적 문제를 동반합니다. 모델이 생성하는 콘텐츠의 신뢰성과 편향 문제는 중요한 이슈로 떠오르고 있으며, 연구자들은 이를 해결하기 위한 다양한 방법론을 모색하고 있습니다. 이는 AI의 사회적 수용성을 높이는 데 필수적입니다.\n",
      "\n",
      "4. **모델의 해석 가능성**: 초대형 언어 모델이 복잡해질수록 그 내부 작동 방식에 대한 해석 가능성도 중요해집니다. 연구자들은 모델의 결정 과정을 이해하고, 이를 통해 더 나은 성능을 이끌어내기 위한 방법을 개발하고 있습니다. 이는 AI의 투명성을 높이고, 사용자와의 신뢰를 구축하는 데 기여합니다.\n",
      "\n",
      "5. **효율성 및 지속 가능성**: 초대형 언어 모델의 훈련과 운영에 필요한 자원 소모가 증가함에 따라, 효율적인 알고리즘과 하드웨어의 개발이 요구됩니다. 이는 환경적 지속 가능성을 고려한 연구 방향으로, AI 기술의 미래를 위해 필수적입니다.\n",
      "\n",
      "결론적으로, 초대형 언어 모델의 발전은 기술적 성과뿐만 아니라 윤리적, 사회적 측면에서도 중요한 의미를 지니고 있습니다. 이러한 다양한 연구 동향은 AI의 발전 방향을 제시하며, 앞으로의 연구와 개발에 있어 중요한 기초가 될 것입니다.\n",
      "=====================\n",
      "질문을 입력하세요: exit\n",
      "대답: 즐거운 대화였어요.\n"
     ]
    }
   ],
   "source": [
    "# KEY설정\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")\n",
    "\n",
    "# 모델로드\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000)\n",
    "\n",
    "# 파일 로드\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"초거대언어모델연구동향.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for doc in docs:\n",
    "    utf8_docs = [doc.page_content.encode('utf-8').decode('utf-8') for doc in docs]\n",
    "\n",
    "# 문서 청크 나누기 2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "    \n",
    "# 벡터 임베딩 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# 리트리버 변환\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "\n",
    "# 템플릿 정의\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an artificial intelligence model researcher. The document describes the latest research trends in super-large language models, including advancements, challenges, and key contributions. Your task is to analyze the document and provide a detailed and insightful response.\"),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n",
    "\n",
    "# 질문 응답 체인 구성\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# 질문 반복 처리\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,   # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()     # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()| contextual_prompt | model\n",
    "\n",
    "# 출력\n",
    "while True:\n",
    "    print('=====================')\n",
    "    query = input(\"질문을 입력하세요: \")\n",
    "\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"대답: 즐거운 대화였어요.\")\n",
    "        break\n",
    "\n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    \n",
    "    print(\"Final Response: \")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8837b3",
   "metadata": {},
   "source": [
    "# 1.\n",
    "- 질문: 최근 초거대 언어모델 연구동향을 알려줘\n",
    "- 대답: 깔끔하게 정리 되었고 내용에 맞는 대답을 한다.\n",
    "\n",
    "# 2. \n",
    "- 질문: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 설명해주세요\n",
    "- 대답: 갑자기 영어로 대답을하여 놀랐다. 내용은 초대형 언어 모델 배포의 윤리적 영향과 사회적 영향을 말하고있다.\n",
    "\n",
    "# 3.\n",
    "- 질문: 방금전 글을 한글로 말해줘\n",
    "- 대답: 첫 번째 질문을 그대로 가져왔다. \n",
    "\n",
    "# 4.\n",
    "- 질문: 각 주제들 중에 가장 중요하다고 생각드는건 무엇이며 왜그런지 한글로 설명해주세요 (한글로 설명 부탁)\n",
    "- 대답: 질문에 관련없는 내용이 나옴\n",
    "\n",
    "\n",
    "## 프롬프트에서 바꾸어야할 점\n",
    "\n",
    "### 이전 프롬프트\n",
    "- system: 인공지능 모델 연구자이십니다. 이 문서에서는 발전, 과제 및 주요 기여를 포함하여 초대형 언어 모델의 최신 연구 동향을 설명합니다. 귀하의 임무는 문서를 분석하고 상세하고 통찰력 있는 답변을 제공하는 것입니다.\n",
    "- user: 본 문서에 언급된 주요 동향과 연구 결과를 중심으로 포괄적인 답변을 부탁드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7c987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
